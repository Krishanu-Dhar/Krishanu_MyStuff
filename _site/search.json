[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Krishanu Dhar",
    "section": "",
    "text": "Hey ## Research Goals"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "Projects/project_title.html",
    "href": "Projects/project_title.html",
    "title": "Project Title",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html#bio",
    "href": "index.html#bio",
    "title": "Krishanu Dhar",
    "section": "",
    "text": "Hey ## Research Goals"
  },
  {
    "objectID": "projects/project_title.html",
    "href": "projects/project_title.html",
    "title": "Analysis of DNA Replication Tracks",
    "section": "",
    "text": "This quarto document summarizes and analyzes DNA replication track data outputted from a Snakemake Pipeline [Link]. Here, I will filter and tidy the data, then plot it out independently, as well as comparitively. Further I will try to predict labeling states within each sample. If the model doesn’t look as robust as I expected, I will use my own algorithm to predict the states and transition points.\n\n\nThere are a couple of things that we should know about the data that we are going to use for the upcoming analyses.\n\nFirst, we have bedfiles, which consist of read IDs and their metadata. These read IDs are unique, because these have DNA replication footprints. These footprints actually look pretty colorful (will see them in just a few moments). To better understand, here is snap of the workflow:\n\n\n\nlibrary(here)\nlibrary(tidyverse)\nlibrary(cowplot)\nlibrary(zoo)\ncat(\"Working from:\", here::here(), \"\\n\")\n\nWorking from: C:/Users/dhark/Documents/GitHub/Krishanu_MyStuff \n\n\nLet’s have a glimpse at one of the bedfiles I mentioned above:\n\ntry_bed &lt;- read_table(\n  here(\"projects\", \"data\", \"bedfiles\", \"NT\", \"leftForks_DNAscent_forkSense.bed\"),\n  comment = \"#\",\n  col_names = FALSE\n)\n\noptions(readr.show_col_types = FALSE)\n# Quick look\nglimpse(try_bed)\n\nRows: 195\nColumns: 9\n$ X1 &lt;chr&gt; \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"ch…\n$ X2 &lt;dbl&gt; 1325962, 5853908, 11261820, 35847942, 38897717, 39298905, 44646358,…\n$ X3 &lt;dbl&gt; 1332304, 5863452, 11274951, 35858135, 38910415, 39311525, 44655386,…\n$ X4 &lt;chr&gt; \"64d3f3d8-4f2f-4c03-ad7d-f3268d7e47ac\", \"8e3a55a6-a88c-4c4f-b52a-70…\n$ X5 &lt;dbl&gt; 1310499, 5839126, 11252034, 35847937, 38894320, 39298565, 44646339,…\n$ X6 &lt;dbl&gt; 1357925, 5869143, 11326927, 35907478, 38920742, 39320633, 44667509,…\n$ X7 &lt;chr&gt; \"rev\", \"rev\", \"rev\", \"fwd\", \"rev\", \"fwd\", \"rev\", \"fwd\", \"rev\", \"fwd…\n$ X8 &lt;dbl&gt; 6306, 9555, 13098, 10012, 12506, 12478, 9022, 3598, 12521, 6140, 67…\n$ X9 &lt;dbl&gt; 0.761731, 0.060901, 0.442901, -3.000000, -3.000000, -3.000000, -3.0…\n\n# Assign proper column names\ncolnames(try_bed) &lt;- c(\n  \"chrom\", \"fork_start\", \"fork_end\", \"read_id\",\n  \"read_start\", \"read_end\", \"strand\",\n  \"fork_length\", \"score\"\n)\n\nglimpse(try_bed)\n\nRows: 195\nColumns: 9\n$ chrom       &lt;chr&gt; \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"c…\n$ fork_start  &lt;dbl&gt; 1325962, 5853908, 11261820, 35847942, 38897717, 39298905, …\n$ fork_end    &lt;dbl&gt; 1332304, 5863452, 11274951, 35858135, 38910415, 39311525, …\n$ read_id     &lt;chr&gt; \"64d3f3d8-4f2f-4c03-ad7d-f3268d7e47ac\", \"8e3a55a6-a88c-4c4…\n$ read_start  &lt;dbl&gt; 1310499, 5839126, 11252034, 35847937, 38894320, 39298565, …\n$ read_end    &lt;dbl&gt; 1357925, 5869143, 11326927, 35907478, 38920742, 39320633, …\n$ strand      &lt;chr&gt; \"rev\", \"rev\", \"rev\", \"fwd\", \"rev\", \"fwd\", \"rev\", \"fwd\", \"r…\n$ fork_length &lt;dbl&gt; 6306, 9555, 13098, 10012, 12506, 12478, 9022, 3598, 12521,…\n$ score       &lt;dbl&gt; 0.761731, 0.060901, 0.442901, -3.000000, -3.000000, -3.000…\n\n\nSecond, we have multiple bedgraph files. Each read ID is associated with two bedgraph files (one for EdU and one for BrdU). Let’s look at a pair of bedgraphs for a read ID.\n\nbrdu_bed &lt;- read_tsv(\n  here(\"projects\", \"data\", \"bedgraphs\", \"NT\", \"BrdU__0b9d33df-6203-4c55-9ac5-c20ce628dde9.bedgraph\")\n)\nedu_bed &lt;- read_tsv(\n  here(\"projects\", \"data\", \"bedgraphs\", \"NT\", \"EdU__0b9d33df-6203-4c55-9ac5-c20ce628dde9.bedgraph\")\n)\n\n# Assigning column names\ncolnames(edu_bed) &lt;- c(\"chrom\", \"start\", \"end\", \"prob_score\")\ncolnames(brdu_bed) &lt;- c(\"chrom\", \"start\", \"end\", \"prob_score\")\nhead(brdu_bed)\n\n# A tibble: 6 × 4\n  chrom   start     end prob_score\n  &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n1 chr16 8110549 8110649    0.00896\n2 chr16 8110539 8110639    0.00882\n3 chr16 8110529 8110629    0.00911\n4 chr16 8110519 8110619    0.00947\n5 chr16 8110509 8110609    0.00951\n6 chr16 8110499 8110599    0.00933\n\nhead(edu_bed)\n\n# A tibble: 6 × 4\n  chrom   start     end prob_score\n  &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n1 chr16 8110549 8110649      0.908\n2 chr16 8110539 8110639      0.851\n3 chr16 8110529 8110629      0.850\n4 chr16 8110519 8110619      0.828\n5 chr16 8110509 8110609      0.806\n6 chr16 8110499 8110599      0.786\n\n\n\nYou might have guessed it from this. These bedgraphs hold information for the probability score of EdU/BrdU (thymidine analogs) across the entire read for every 100 base pairs (bin size)."
  },
  {
    "objectID": "projects/project_title.html#about-this-site",
    "href": "projects/project_title.html#about-this-site",
    "title": "Analysis of DNA Replication Tracks",
    "section": "",
    "text": "This document summarizes and analyzes DNA replication track data outputted from a Snakemake Pipeline. Here, I will filter and tidy the data, then plot it out independently, as well as comparitively. Further I will try to predict states (labeling) within the sample."
  },
  {
    "objectID": "projects/project_title.html#description",
    "href": "projects/project_title.html#description",
    "title": "Analysis of DNA Replication Tracks",
    "section": "",
    "text": "This quarto document summarizes and analyzes DNA replication track data outputted from a Snakemake Pipeline [Link]. Here, I will filter and tidy the data, then plot it out independently, as well as comparitively. Further I will try to predict labeling states within each sample. If the model doesn’t look as robust as I expected, I will use my own algorithm to predict the states and transition points.\n\n\nThere are a couple of things that we should know about the data that we are going to use for the upcoming analyses.\n\nFirst, we have bedfiles, which consist of read IDs and their metadata. These read IDs are unique, because these have DNA replication footprints. These footprints actually look pretty colorful (will see them in just a few moments). To better understand, here is snap of the workflow:\n\n\n\nlibrary(here)\nlibrary(tidyverse)\nlibrary(cowplot)\nlibrary(zoo)\ncat(\"Working from:\", here::here(), \"\\n\")\n\nWorking from: C:/Users/dhark/Documents/GitHub/Krishanu_MyStuff \n\n\nLet’s have a glimpse at one of the bedfiles I mentioned above:\n\ntry_bed &lt;- read_table(\n  here(\"projects\", \"data\", \"bedfiles\", \"NT\", \"leftForks_DNAscent_forkSense.bed\"),\n  comment = \"#\",\n  col_names = FALSE\n)\n\noptions(readr.show_col_types = FALSE)\n# Quick look\nglimpse(try_bed)\n\nRows: 195\nColumns: 9\n$ X1 &lt;chr&gt; \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"ch…\n$ X2 &lt;dbl&gt; 1325962, 5853908, 11261820, 35847942, 38897717, 39298905, 44646358,…\n$ X3 &lt;dbl&gt; 1332304, 5863452, 11274951, 35858135, 38910415, 39311525, 44655386,…\n$ X4 &lt;chr&gt; \"64d3f3d8-4f2f-4c03-ad7d-f3268d7e47ac\", \"8e3a55a6-a88c-4c4f-b52a-70…\n$ X5 &lt;dbl&gt; 1310499, 5839126, 11252034, 35847937, 38894320, 39298565, 44646339,…\n$ X6 &lt;dbl&gt; 1357925, 5869143, 11326927, 35907478, 38920742, 39320633, 44667509,…\n$ X7 &lt;chr&gt; \"rev\", \"rev\", \"rev\", \"fwd\", \"rev\", \"fwd\", \"rev\", \"fwd\", \"rev\", \"fwd…\n$ X8 &lt;dbl&gt; 6306, 9555, 13098, 10012, 12506, 12478, 9022, 3598, 12521, 6140, 67…\n$ X9 &lt;dbl&gt; 0.761731, 0.060901, 0.442901, -3.000000, -3.000000, -3.000000, -3.0…\n\n# Assign proper column names\ncolnames(try_bed) &lt;- c(\n  \"chrom\", \"fork_start\", \"fork_end\", \"read_id\",\n  \"read_start\", \"read_end\", \"strand\",\n  \"fork_length\", \"score\"\n)\n\nglimpse(try_bed)\n\nRows: 195\nColumns: 9\n$ chrom       &lt;chr&gt; \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"c…\n$ fork_start  &lt;dbl&gt; 1325962, 5853908, 11261820, 35847942, 38897717, 39298905, …\n$ fork_end    &lt;dbl&gt; 1332304, 5863452, 11274951, 35858135, 38910415, 39311525, …\n$ read_id     &lt;chr&gt; \"64d3f3d8-4f2f-4c03-ad7d-f3268d7e47ac\", \"8e3a55a6-a88c-4c4…\n$ read_start  &lt;dbl&gt; 1310499, 5839126, 11252034, 35847937, 38894320, 39298565, …\n$ read_end    &lt;dbl&gt; 1357925, 5869143, 11326927, 35907478, 38920742, 39320633, …\n$ strand      &lt;chr&gt; \"rev\", \"rev\", \"rev\", \"fwd\", \"rev\", \"fwd\", \"rev\", \"fwd\", \"r…\n$ fork_length &lt;dbl&gt; 6306, 9555, 13098, 10012, 12506, 12478, 9022, 3598, 12521,…\n$ score       &lt;dbl&gt; 0.761731, 0.060901, 0.442901, -3.000000, -3.000000, -3.000…\n\n\nSecond, we have multiple bedgraph files. Each read ID is associated with two bedgraph files (one for EdU and one for BrdU). Let’s look at a pair of bedgraphs for a read ID.\n\nbrdu_bed &lt;- read_tsv(\n  here(\"projects\", \"data\", \"bedgraphs\", \"NT\", \"BrdU__0b9d33df-6203-4c55-9ac5-c20ce628dde9.bedgraph\")\n)\nedu_bed &lt;- read_tsv(\n  here(\"projects\", \"data\", \"bedgraphs\", \"NT\", \"EdU__0b9d33df-6203-4c55-9ac5-c20ce628dde9.bedgraph\")\n)\n\n# Assigning column names\ncolnames(edu_bed) &lt;- c(\"chrom\", \"start\", \"end\", \"prob_score\")\ncolnames(brdu_bed) &lt;- c(\"chrom\", \"start\", \"end\", \"prob_score\")\nhead(brdu_bed)\n\n# A tibble: 6 × 4\n  chrom   start     end prob_score\n  &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n1 chr16 8110549 8110649    0.00896\n2 chr16 8110539 8110639    0.00882\n3 chr16 8110529 8110629    0.00911\n4 chr16 8110519 8110619    0.00947\n5 chr16 8110509 8110609    0.00951\n6 chr16 8110499 8110599    0.00933\n\nhead(edu_bed)\n\n# A tibble: 6 × 4\n  chrom   start     end prob_score\n  &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n1 chr16 8110549 8110649      0.908\n2 chr16 8110539 8110639      0.851\n3 chr16 8110529 8110629      0.850\n4 chr16 8110519 8110619      0.828\n5 chr16 8110509 8110609      0.806\n6 chr16 8110499 8110599      0.786\n\n\n\nYou might have guessed it from this. These bedgraphs hold information for the probability score of EdU/BrdU (thymidine analogs) across the entire read for every 100 base pairs (bin size)."
  },
  {
    "objectID": "projects/project_title.html#workflow",
    "href": "projects/project_title.html#workflow",
    "title": "Analysis of DNA Replication Tracks",
    "section": "Workflow",
    "text": "Workflow\n\nOrganize and tidy the data for better clarity and future use\nPlot the data\nFinding out the transition points of each read and calculating fork speeds for the samples\n\n\nOrganizing and tidying our data\n\n# ===Non-treated Sample (NT)===\nleft_df &lt;- read_table(\n  here(\"projects\", \"data\", \"bedfiles\", \"NT\", \"leftForks_DNAscent_forkSense.bed\"),\n  comment = \"#\",\n  col_names = FALSE\n)\nright_df &lt;- read_table(\n  here(\"projects\", \"data\", \"bedfiles\", \"NT\", \"rightForks_DNAscent_forkSense.bed\"),\n  comment = \"#\",\n  col_names = FALSE\n)\norigin_df &lt;- read_table(\n  here(\"projects\", \"data\", \"bedfiles\", \"NT\", \"origins_DNAscent_forkSense.bed\"),\n  comment = \"#\",\n  col_names = FALSE\n)\ntermination_df &lt;- read_table(\n  here(\"projects\", \"data\", \"bedfiles\", \"NT\", \"terminations_DNAscent_forkSense.bed\"),\n  comment = \"#\",\n  col_names = FALSE\n)\n# Set column names (Origins and Terminations have different structure)\ncolnames(left_df) &lt;- colnames(right_df) &lt;- c(\n  \"chrom\", \"fork_start\", \"fork_end\", \"read_id\",\n  \"read_start\", \"read_end\", \"strand\",\n  \"fork_length\", \"score\"\n)\ncolnames(origin_df) &lt;- colnames(termination_df) &lt;- c(\"chrom\", \"fork_start\", \"fork_end\", \"read_id\", \"read_start\", \"read_end\", \"strand\")\n\n# Merge left and right forks\nmerged_df &lt;- rbind(left_df, right_df)\n\n# Extract read IDs\nmerged_ids &lt;- unique(trimws(as.character(merged_df$read_id)))\nexclude_ids &lt;- unique(trimws(as.character(c(origin_df$read_id, termination_df$read_id))))\n\n# Filter out excluded read IDs\nfiltered_ids &lt;- setdiff(merged_ids, exclude_ids)\n\nfiltered_df_NT &lt;- merged_df |&gt;\n  filter(read_id %in% filtered_ids)\n\n# Optional: Exclude reads with score == -3\nfiltered_df_NT &lt;- filtered_df_NT |&gt; \n  filter(score != -3.000000)\n\n# ===Treated sample (Auxin)===\n\nleft_df &lt;- read_table(\n  here(\"projects\", \"data\", \"bedfiles\", \"Auxin\", \"leftForks_DNAscent_forkSense.bed\"),\n  comment = \"#\",\n  col_names = FALSE\n)\nright_df &lt;- read_table(\n  here(\"projects\", \"data\", \"bedfiles\", \"Auxin\", \"rightForks_DNAscent_forkSense.bed\"),\n  comment = \"#\",\n  col_names = FALSE\n)\norigin_df &lt;- read_table(\n  here(\"projects\", \"data\", \"bedfiles\", \"Auxin\", \"origins_DNAscent_forkSense.bed\"),\n  comment = \"#\",\n  col_names = FALSE\n)\ntermination_df &lt;- read_table(\n  here(\"projects\", \"data\", \"bedfiles\", \"Auxin\", \"terminations_DNAscent_forkSense.bed\"),\n  comment = \"#\",\n  col_names = FALSE\n)\n# Set column names (Origins and Terminations have different structure)\ncolnames(left_df) &lt;- colnames(right_df) &lt;- c(\n  \"chrom\", \"fork_start\", \"fork_end\", \"read_id\",\n  \"read_start\", \"read_end\", \"strand\",\n  \"fork_length\", \"score\"\n)\ncolnames(origin_df) &lt;- colnames(termination_df) &lt;- c(\"chrom\", \"fork_start\", \"fork_end\", \"read_id\", \"read_start\", \"read_end\", \"strand\")\n\n# Merge left and right forks\nmerged_df &lt;- rbind(left_df, right_df)\n\n# Extract read IDs\nmerged_ids &lt;- unique(trimws(as.character(merged_df$read_id)))\nexclude_ids &lt;- unique(trimws(as.character(c(origin_df$read_id, termination_df$read_id))))\n\n# Filter out excluded read IDs\nfiltered_ids &lt;- setdiff(merged_ids, exclude_ids)\n\nfiltered_df_Aux &lt;- merged_df |&gt;\n  filter(read_id %in% filtered_ids)\n\n# Optional: Exclude reads with score == -3\nfiltered_df_Aux &lt;- filtered_df_Aux |&gt; \n  filter(score != -3.000000)\n\nfiltered_df_NT &lt;- as.data.frame(filtered_df_NT)\nfiltered_df_Aux &lt;- as.data.frame(filtered_df_Aux)\n\n# Viewing the filtered dataframes\nglimpse(filtered_df_NT)\n\nRows: 166\nColumns: 9\n$ chrom       &lt;chr&gt; \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"chr1\", \"c…\n$ fork_start  &lt;dbl&gt; 1325962, 5853908, 11261820, 104445678, 169175860, 17758184…\n$ fork_end    &lt;dbl&gt; 1332304, 5863452, 11274951, 104451816, 169189462, 17760261…\n$ read_id     &lt;chr&gt; \"64d3f3d8-4f2f-4c03-ad7d-f3268d7e47ac\", \"8e3a55a6-a88c-4c4…\n$ read_start  &lt;dbl&gt; 1310499, 5839126, 11252034, 104429126, 169154802, 17756058…\n$ read_end    &lt;dbl&gt; 1357925, 5869143, 11326927, 104464577, 169209614, 17761424…\n$ strand      &lt;chr&gt; \"rev\", \"rev\", \"rev\", \"fwd\", \"fwd\", \"rev\", \"rev\", \"rev\", \"r…\n$ fork_length &lt;dbl&gt; 6306, 9555, 13098, 6140, 13472, 20531, 15511, 14073, 9069,…\n$ score       &lt;dbl&gt; 0.761731, 0.060901, 0.442901, 0.143650, 0.626286, 0.323392…\n\nglimpse(filtered_df_Aux)\n\nRows: 145\nColumns: 9\n$ chrom       &lt;chr&gt; \"chr1\", \"chr1\", \"chr1\", \"chr10\", \"chr10\", \"chr10\", \"chr11\"…\n$ fork_start  &lt;dbl&gt; 42555757, 74913117, 88048670, 5107329, 35278521, 101796909…\n$ fork_end    &lt;dbl&gt; 42567801, 74938602, 88069287, 5127677, 35289612, 101811662…\n$ read_id     &lt;chr&gt; \"b12f510a-f17b-40b7-97ab-cafe779352a3\", \"832eb7fc-dea3-468…\n$ read_start  &lt;dbl&gt; 42523710, 74885160, 88000876, 5072168, 35242164, 101772252…\n$ read_end    &lt;dbl&gt; 42622859, 74961619, 88162060, 5140342, 35308086, 101813531…\n$ strand      &lt;chr&gt; \"rev\", \"fwd\", \"rev\", \"fwd\", \"rev\", \"rev\", \"fwd\", \"rev\", \"f…\n$ fork_length &lt;dbl&gt; 11948, 25421, 20462, 20119, 10989, 14510, 20322, 10766, 13…\n$ score       &lt;dbl&gt; 0.092489, 0.056514, 0.222898, 0.083192, 0.149709, 0.359784…\n\n# Saving the filtered bedfiles for future use\nwrite_tsv(filtered_df_NT, \n            here(\"projects\", \"data\",\"bedfiles\", \"NT\", \"final_filtered.bed\"))\nwrite_tsv(filtered_df_Aux, \n            here(\"projects\", \"data\",\"bedfiles\", \"Auxin\", \"final_filtered.bed\"))\n\n\n\nPlotting the Data\nWe are going to now see how the ‘.bedgraph’ files look. If you open a pair of these bedgraphs in IGV (Integartive Genome Viewer), this is what we see.\n\n\n\n\n\nI am going to first make an aggregate plot of them (one for each of the samples). To start, we will need the help of a few user-defined functions. We will call them helper functions. These functions will have multiple input parameters, and at the same time they will return somethings as they are called. For simplicity’s sake, I am not showing the functions. I will directly show where I am calling the parent function, where all the helper functions are stored.\n\n# Setting the directory where our input data is\ndata_dir &lt;- here(\"projects\", \"data/bedgraphs\")\n\n# List your sample names\nsample_names &lt;- c(\"NT\", \"Auxin\")\n\n# Load and annotate each sample's data\nsummary_all &lt;- map_dfr(sample_names, function(sample_name) {\n  df &lt;- make_aggregate_plot_df(file.path(data_dir, sample_name), sample_name)\n  df$sample_name &lt;- factor(sample_name, levels = sample_names)\n  \n  # Also add the boundaries as columns (repeated per row)\n  boundaries &lt;- df[1, c(\"edu_start\", \"brdu_start\", \"brdu_end\")]\n  df$edu_start &lt;- boundaries$edu_start\n  df$brdu_start &lt;- boundaries$brdu_start\n  df$brdu_end &lt;- boundaries$brdu_end\n  \n  return(df)\n})\n\n# Plot with facet grid\nsummary_all |&gt;\n  ggplot(aes(x = x, y = median_diff)) +\n  geom_line(color = \"blue\") +\n  #geom_smooth(method = \"loess\", span = 0.2, se = TRUE, color = \"lightblue\") +\n  geom_vline(aes(xintercept = edu_start), linetype = \"dashed\", color = \"purple\") +\n  geom_vline(aes(xintercept = brdu_start), linetype = \"dashed\", color = \"darkgreen\") +\n  geom_vline(aes(xintercept = brdu_end), linetype = \"dashed\", color = \"darkred\") +\n  geom_text(aes(x = edu_start, y = 0.5, label = round(edu_start)), angle = 45, vjust = -0.5, color = \"purple\") +\n  geom_text(aes(x = brdu_start, y = 0.5, label = round(brdu_start)), angle = 45, vjust = -0.5, color = \"darkgreen\") +\n  geom_text(aes(x = brdu_end, y = -0.5, label = round(brdu_end)), angle = 45, vjust = -0.5, color = \"darkred\") +\n  labs(title = \"Aggregate BrdU - EdU signal\", x = \"Relative Position (bp)\", y = \"Median Δ signal (BrdU-EdU)\") +\n  facet_grid(sample_name ~.) +\n  theme_cowplot()\n\n\n\n\n\n\n\n\n\n\nFinding the transition points and calculating the DNA replication fork speeds across our samples\nFor this, I have to get the data of each track. So, I have to process each read ID from each of the samples.\n\ndata_dir &lt;- here(\"projects/data/bedgraphs\")\nsample_names &lt;- c(\"NT\", \"Auxin\")\n\nplot_each_track &lt;- function(bedgraph_dir) {\n  save_dir     &lt;- file.path(bedgraph_dir, \"processed_reads\")\n  aligned_dir  &lt;- file.path(bedgraph_dir, \"aligned\")\n  plots_dir    &lt;- file.path(bedgraph_dir, \"plots\")\n\n  # Create directories if they don't exist\n  dir.create(aligned_dir, recursive = TRUE, showWarnings = FALSE)\n  dir.create(plots_dir, recursive = TRUE, showWarnings = FALSE)\n\n  # Step 1: Save processed reads\n  paired_tracks &lt;- save_bedgraph_tracks(bedgraph_dir, save_dir = save_dir)\n\n  # Step 2: Initialize boundary table\n  boundary_table &lt;- data.frame(\n    read_id     = character(),\n    edu_start   = numeric(),\n    brdu_start  = numeric(),\n    brdu_end    = numeric(),\n    edu_track   = numeric(),\n    brdu_track  = numeric(),\n    full_track  = numeric(),\n    fork_speed  = numeric(),\n    stringsAsFactors = FALSE\n  )\n\n  # Step 3: Read saved TSVs\n  tsv_files &lt;- list.files(save_dir, pattern = \"\\\\.tsv$\", full.names = TRUE)\n\n  for (tsv_file in tsv_files) {\n    read_id &lt;- tools::file_path_sans_ext(basename(tsv_file))\n    df &lt;- read.table(tsv_file, header = TRUE, sep = \"\\t\")\n\n    # Step 4: Align and detect boundaries\n    aligned_df &lt;- align_diff_by_minimum(df)\n    \n    # Now check for x validity\n    if (!\"x\" %in% colnames(aligned_df) || all(is.na(aligned_df$x))) {\n      message(\"Skipping \", read_id, \": x column missing or all NA after alignment\")\n      next\n    }\n    aligned_detected_df &lt;- detect_individual_boundaries(aligned_df)\n\n    # Skip if x or smoothed_diff is entirely NA\n    if (anyNA(aligned_detected_df$x) || all(is.na(aligned_detected_df$smoothed_diff))) {\n      message(\"Skipping \", read_id, \": invalid or missing smoothed_diff\")\n      next\n    }\n\n    # Extract boundary values\n    edu_start_val  &lt;- unique(aligned_detected_df$edu_start)\n    brdu_start_val &lt;- unique(aligned_detected_df$brdu_start)\n    brdu_end_val   &lt;- unique(aligned_detected_df$brdu_end)\n\n    # Skip if any boundary is NA\n    if (anyNA(c(edu_start_val, brdu_start_val, brdu_end_val))) {\n      message(\"Skipping \", read_id, \": one or more boundaries are NA\")\n      next\n    }\n\n    # Step 5: Save aligned TSV\n    aligned_path &lt;- file.path(aligned_dir, paste0(read_id, \".tsv\"))\n    write.table(aligned_detected_df, file = aligned_path, sep = \"\\t\", row.names = FALSE, quote = FALSE)\n\n    # Step 6: Save boundary info\n    boundary_table &lt;- rbind(boundary_table, data.frame(\n      read_id     = read_id,\n      edu_start   = edu_start_val,\n      brdu_start  = brdu_start_val,\n      brdu_end    = brdu_end_val,\n      edu_track   = brdu_start_val - edu_start_val,\n      brdu_track  = brdu_end_val - brdu_start_val,\n      full_track  = brdu_end_val - edu_start_val,\n      fork_speed  = (brdu_end_val - edu_start_val) / 20000\n    ))\n\n    # Step 7: Plot\n    p &lt;- ggplot(aligned_detected_df, aes(x = x, y = smoothed_diff)) +\n      geom_line(color = \"black\") +\n      geom_vline(xintercept = edu_start_val,  color = \"purple\",    linetype = \"dashed\") +\n      geom_vline(xintercept = brdu_start_val, color = \"darkgreen\", linetype = \"dashed\") +\n      geom_vline(xintercept = brdu_end_val,   color = \"darkred\",   linetype = \"dashed\") +\n      annotate(\"text\", x = edu_start_val,  y = max(aligned_detected_df$diff, na.rm = TRUE), label = round(edu_start_val),  color = \"purple\",    vjust = -0.5, angle = 45) +\n      annotate(\"text\", x = brdu_start_val, y = max(aligned_detected_df$diff, na.rm = TRUE), label = round(brdu_start_val), color = \"darkgreen\", vjust = -0.5, angle = 45) +\n      annotate(\"text\", x = brdu_end_val,   y = max(aligned_detected_df$diff, na.rm = TRUE), label = round(brdu_end_val),   color = \"darkred\",   vjust = -0.5, angle = 45) +\n      labs(title = paste(\"BrdU - EdU for\", read_id), x = \"x\", y = \"diff\") +\n      theme_cowplot()\n\n    plot_path &lt;- file.path(plots_dir, paste0(read_id, \".png\"))\n    ggsave(plot_path, plot = p, width = 6, height = 4)\n  }\n\n  # Step 8: Save summary CSV\n  summary_csv_path &lt;- file.path(plots_dir, \"boundary_summary.csv\")\n  write.csv(boundary_table, file = summary_csv_path, row.names = FALSE)\n\n  invisible(NULL)\n}\n\n\n\nfor (sample in sample_names) {\n  sample_dir &lt;- file.path(data_dir, sample)\n  message(\"Processing sample: \", sample)\n  plot_each_track(sample_dir)\n  \n}\n\nNow, let’s see how one of these plots look like. First let us look at the plot if the raw ‘diff’ values were plotted against ‘x’.\n\n\n\n\n\nReally noisy right. Now, let’s look at the line_plot of the same read ID when smoothed using the ‘zoo’ package.\n\n\n\n\n\nIt does look like it is detecting the boundaries and transition points accurately. So, I went forward with the thresholds used here to measure and estimate the fork speeds.\nNow, for comparing data of each track for Non-treated vs Auxin-treated.\n\n# Read and combine the boundary summary files\nboundary_data &lt;- map_dfr(sample_names, function(sample) {\n  csv_path &lt;- file.path(data_dir, sample, \"plots\", \"boundary_summary.csv\")\n  if (file.exists(csv_path)) {\n    df &lt;- read.csv(csv_path)\n    df$sample &lt;- sample\n    return(df)\n  } else {\n    warning(\"Missing file: \", csv_path)\n    return(NULL)\n  }\n})\n\n# Plot violin plot with jittered points\nggplot(boundary_data, aes(x = sample, y = fork_speed, fill = sample, )) +\n  geom_boxplot(outliers = TRUE, outlier.colour = \"darkred\", alpha = 0.5) +\n  geom_jitter(width = 0.15, size = 1, alpha = 0.7, color = \"black\") +\n  labs(title = \"Fork Speed Distribution\", y = \"Fork Speed (kb/min)\", x = \"\") +\n  theme_cowplot()"
  }
]